\section{Implementation}
\label{sec:Implementation}

\subsection{Technologies Used}
NeuraViz was developed with a multitude of standard web technologies used in conjunction to build the classic client-server architecture used by this project. The chosen technologies were used for their stable and well-documented nature, as well as their ability to interact with libraries and frameworks specific to neural networks. This section describes what technologies were used for each of the three constituent components of NeuraViz.

\subsubsection{Client}
The client component is the primary interface for user interaction, and therefore it must be visually appealing and responsive. In researching available web frameworks for building frontend web applications, a number of possibilities were considered including ReactJS \cite{react}, Angular \cite{angular}, and Svelte \cite{svelte}. While ReactJS would have been a good choice because of its popularity and the developer's prior experience with it, Svelte was eventually chosen for its simplicity and performance. 

Svelte is a relatively new web framework that is similar to ReactJS in that it is component-based, but it is different in that it compiles the components into vanilla JavaScript at build time. This means that the final product is much smaller and faster than a ReactJS application, which must include the React library in the final product. Svelte also has a simpler syntax than ReactJS, which makes it easier to learn and use. In particular, Svelte's feature set across reactivity of its components, ease of implementing special features such as animations, and built-in global store system turned out to be especially helpful during the development of NeuraViz. Svelte also natively supports TypeScript, a superset of JavaScript that introduces a strong static type system and a powerful type inference system that helped keep the codebase clean and maintainable, while still providing the freedom to work in a web environment seamlessly.

Though Svelte is a powerful and featureful framework on its own, two shortcomings were identified during NeuraViz's development that had to be overcome with additional libraries. Svelte's component system does a fantastic job of abstracting components into small, reusable pieces, but it lacks prebuilt components that would keep the application's look and feel consistent and the development rapid. To remedy this problem the Flowbite Svelte library \cite{flowbite} was used. Flowbite provides prebuilt Svelte components that fulfill many of the necessary functionalities of a web application. For example, it contains components such as buttons, text boxes, dialogs, and more. Being built on top of TailwindCSS \cite{tailwind}, Flowbite also provides excellent support for light and dark application themes. As its second shortcoming, Svelte does not include functionality for sending or receiving HTTP requests. While JavaScript's native fetch function would work for this, Axios \cite{axios} provides a much cleaner experience for handling HTTP calls and responses. Axios also provides support for handling the asynchronous nature of HTTP requests via JavaScript's promise API and callback functions.

Graph visualization is being the most critical feature of NeuraViz and it was a major consideration when determining client technologies. To aid in the construction of the graph visualization, the D3.js library \cite{d3} was used. D3 is a highly customizable JavaScript library for creating visualizations of data in a variety of formats. It works by providing abstractions on the DOM for building SVG elements easily and dynamically. In addition to providing methods for creating large numbers of static SVG elements, D3 also contains abstractions for dealing with animations and movement such as the functionality in NeuraViz for dragging the graph around and zooming in and out. The modular nature of the library also makes it perfect for dealing with the programmatic generation of complex visualizations such as those necessary in this project.

\subsubsection{Server}
Prior to beginning development on NeuraViz, the developer spent a semester doing an independent research project comparing various machine learning frameworks. During this research, PyTorch, Keras, and scikit-learn \cite{scikit} were explored in depth. Standardized models were also written in each of the frameworks, which were then used to test NeuraViz's parsing algorithm. One of the models was trained to classify data in the famous Iris data set \cite{iris}, a set of data containing measurements of three different species of iris flowers and their corresponding species. In addition, a much larger model was created for classifying handwritten digits from the MNIST data set \cite{mnist}. The smaller iris models helped test basic functionality of NeuraViz with layers of nodes that were small enough to visualize in full. When testing the MNIST models, it was also discovered that some models would be too big to visualize effectively, so it was decided to add the functionality of collapsing layers into Node Collections and Link Collections. Variations on these models were also added to test combinations of collapsed and uncollapsed layers. These models can all be found in the test/input\_files directory in the NeuraViz repository \cite{neuraviz_repo}.

When deciding what programming language to use for the server side of NeuraViz, a major consideration was the integration with the uploaded neural network models and the complexities of parsing them. The eventual decision was that it would not just be easier, but also more maintainable to include the libraries themselves and then extract the necessary information from the objects rather than parsing the model files manually. Because most popular machine learning frameworks are written for Python, it made sense to write NeuraViz's server in Python as well. 

To accommodate this language choice fully, Quart \cite{quart} was selected for managing the server side of the application for its simplicity, great documentation, and support for asynchronous request handling. Quart is a partial rewrite of the popular Python web framework Flask \cite{flask}, with support for asynchronous operations included. In NeuraViz, Quart is simply used as an API manager and to serve the static frontend compiled with Svelte, though it does have support for compiling and serving the HTML, CSS, and JavaScript necessary to run a web application itself. Managing an API in Quart is as simple as defining async handler functions and adding Quart's decorator to specify what route should call that function. While the parsing operations are complex, the number of endpoints that this API requires is relatively small. Table \ref{tab:api_endpoints} shows the full list of routes that the server provides.

\begin{center}
    \begin{tabular}{|l|l|}
        \hline
        \rowcolor{gray!40} Endpoint & \textbf{POST /graph} \\
        \hline
        Description & Upload the graph model and retrieve the intermittent representation. \\
        \hline
        Inputs & The graph model as a file in the request \\
        \hline
        Responses & 200 OK - Graph representation is returned \\
        & 400 Bad Request - The file was not valid \\
        & 501 Not Implemented - The file type is not supported \\
        \hline
        \rowcolor{gray!40} Endpoint & \textbf{GET /tikz}\\
        \hline
        Description & Retrieve the session's graph as a \LaTeX{} file using TikZ (in light mode) \\
        \hline
        Inputs & None \\
        \hline
        Responses & 200 OK - \LaTeX{} is returned as a string \\
        & 400 Bad Request - No graph was found in the session \\
        \hline
        \rowcolor{gray!40} Endpoint & \textbf{GET /tikz/dark} \\
        \hline 
        Description & Get the dark mode version of the TikZ representation \\
        \hline
        Inputs & None \\
        \hline
        Responses & 200 OK - \LaTeX{} is returned as a string \\
        & 400 Bad Request - No graph was found in the session \\
        \hline
    \end{tabular}
    \captionof{table}{Server API Endpoints}
    \label{tab:api_endpoints}
\end{center}

Currently, NeuraViz supports visualizing models created with Keras and PyTorch. As such, both of those frameworks are also included in the server portion of the application. When the graph endpoint is hit, the correct framework is determined based on the file extension of the uploaded file. From there, the framework is used to decode the model into a Python object, which is then parsed to retrieve the information needed for NeuraViz's visualization. The object parsing algorithm differs slightly between the frameworks, but the general idea is the same. Both frameworks store the model as a series of layers, each of which contains information about the layer's type, activation function, and input and output shapes. From the input and output shapes, the number of nodes in each layer can be determined. The layer data also contains information about the weights on links and the biases on nodes, which are incorporated into the visualization.

\subsubsection{Data Layer}
NeuraViz has a relatively simple data layer as the only persistent data is session information. Due to this simple nature, MongoDB \cite{mongodb} was decided on for storing the data. Mongo is a NoSQL database implementation that Python has good support for through the PyMongo package \cite{pymongo}. Models were written for each of the constituent parts of the stored graph as well as for the session itself. A custom module was also written for managing the sessions to encourage session management to be integrated into each API endpoint during development.

\subsection{Development}
The development of NeuraViz was completed over the course of 22 one-week long sprints. The first two sprints consisted primarily of designing the application. Sprints 3-10 focused on building the main functionality of the application for models uploaded with PyTorch. The remaining sprints added Keras support and additional features. PyTorch was chosen first because it was identified as one of the simplest to work with during the preliminary research and because it is incredibly popular. 

Design work on the application began by thinking through a set of desired features. Because NeuraViz isn't built for a particular client, this primarily consisted of the developer coming up with ideas and those ideas being vetted by the project advisor to come up with a final concept for the project. Once there was a solid understanding of at least the basic functionality that the application would fulfill, a user interface mockup, (see Figure \ref{fig:ui_mockup}) was created to give a visual representation of what the application would look like. This design step also served to iron out some key focus points such as the desire for pan and zoom functionality and unobtrusive locations for settings and controls before development on the actual application began. The UI mockup was heavily referenced when creating the actual application UI, and the final product is very similar to what the mockup originally showed.

Once the design was ready, development began. The first step was learning the two new frameworks (namely Svelte and Quart) and working to get them integrated with each other. The developer had previous experience with ReactJS, so Svelte's similar structure made the learning curve relatively small, and the concepts were picked up quickly. With experience building web application backends, Quart was also relatively easy to pick up and get working. The first few sprints after design were spent getting these two frameworks set up, laying out the basic structure of the frontend by following the mockups, and setting up the backend to serve the compiled frontend and handle the necessary API endpoints.

After the basic structure of the application was in place, the next step was figuring out how to use D3.js to create the visualization of the graph. Because the server-side graph parser had not been completed at this point, the graph structure was hard-coded in the application to allow for quick iteration on what the data needed to look like for the visualization to work and be as easy as possible to transmit across the network. An additional major step in this process was getting the pan and zoom functionality of the graph visualization working properly. While D3 provides some of the functionality, getting it working smoothly and dynamically integrated with the NeuraViz logic was a significant challenge that required a lot of trial and error. In particular, a major challenge early on was ensuring that the panning was smooth. The initial implementation was very choppy and hard to use, and correcting that took multiple hours.

The next major step was getting the server to parse the uploaded model files. This was a significant challenge as the structure of the model files is complex and not well documented. Because of this complexity, it was decided to let the frameworks parse the models themselves, and to extract the necessary information from the objects that the frameworks produced. While this cut out some of the complexity of trying to parse the files the frameworks produce, it still maintained the complexity of dealing with the object-oriented representation of the objects in Python. Most machine learning frameworks expect developers to build, train, and execute models through their frameworks, but parsing those models out to alternative representations is generally not an intended use-case. Because of this, documentation on how the objects are structured and exactly where the necessary information is stored is sparse. An extensive amount of time was required to investigate the object structure in each framework and determine how that information could be converted into NeuraViz's standardized representation. To speed up this process, PyTorch alone was focused on initially, and then support for Keras models was added later.

Once server support for parsing PyTorch models and frontend graph visualization were complete, additional features could be added to further enhance the application. Some of the more useful additional features included adding support for activation function representations on the graph, exporting the visualization to \LaTeX{} or SVG, and color-coding model parts to indicate more information at a glance. These features were added toward the second half of the development process.

\subsection{Deployment}
Being a web application, deployment of NeuraViz is a complex process that involves multiple steps. The first step is to compile the Svelte frontend into static HTML, CSS, and JavaScript files. This is done by running the command \texttt{npm run build} in the frontend directory. This command compiles the Svelte code into a set of static files that can be served by a web server. The next step is to copy these files into the server directory so the backend portion of the application can serve up these files. The final step is to start the Quart server, which listens for incoming requests on port 5000 by default. Once the server is running, the application can be accessed by navigating to \texttt{http://localhost:5000} in a web browser.

However, running the the application on localhost does not make it available to the internet as a whole. To make the application accessible to the public, it was deployed to a private web server and routed from \href{https://neuraviz.bennettwendorf.dev}{https://neuraviz.bennettwendorf.dev}. The private server runs Ubuntu 22.04 LTS and PM2 \cite{pm2} was used to help manage the process and allow it to automatically restart when the server restarts.

To speed up deployment to the server, Github Actions \cite{github_actions} was used to automatically build and deploy the application whenever a new commit was pushed to the main branch. The action itself works by setting up a VPN connection to the server and using SSH to run a script on the server. The action configuration is shown in Listing \ref{lst:action_config}.

\begin{center}
    \lstinputlisting[caption={Github Action Configuration}, label={lst:action_config}, float=htb, language=yaml]{../.github/workflows/deploy.yml}
\end{center}

The build script referenced in the configuration file begins by pulling new changes from the remote Github repository. It then cleans all old build files to ensure that everything gets rebuilt fresh. Once the environment is clean, it ensures that all project dependencies are up to date on the server, and installs any new ones if needed. It then recompiles the Svelte frontend and copies it into the necessary location in the backend. Finally, the script uses PM2 to restart the web server process and serve the new version of the application. The full build script is shown in Listing \ref{lst:build_script}.